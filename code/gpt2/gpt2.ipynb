{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import gc\n",
    "import random\n",
    "import re\n",
    "import operator\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import pkg_resources\n",
    "import scipy.stats as stats\n",
    "import sys\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader,TensorDataset,Dataset\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score,roc_auc_score,log_loss\n",
    "\n",
    "\n",
    "# stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "lc = LancasterStemmer()\n",
    "from nltk.stem import SnowballStemmer\n",
    "sb = SnowballStemmer(\"english\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import shutil\n",
    "\n",
    "def seed_everything(SEED=42):\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def init_func(worker_id):\n",
    "    np.random.seed(SEED+worker_id)\n",
    "\n",
    "SEED=42\n",
    "seed_everything(SEED=SEED)\n",
    "\n",
    "tqdm.pandas()\n",
    "t1 = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pip/_internal/commands/install.py:207: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\r\n",
      "  cmdoptions.check_install_build_global(options)\r\n",
      "Created temporary directory: /tmp/pip-ephem-wheel-cache-5ibrgn_b\r\n",
      "Created temporary directory: /tmp/pip-req-tracker-8txmqvn6\r\n",
      "Created requirements tracker '/tmp/pip-req-tracker-8txmqvn6'\r\n",
      "Created temporary directory: /tmp/pip-install-8kkqgtos\r\n",
      "Processing /kaggle/input/nvidiaapex/repository/NVIDIA-apex-39e153a\r\n",
      "  Created temporary directory: /tmp/pip-req-build-nj3yyggs\r\n",
      "  Added file:///kaggle/input/nvidiaapex/repository/NVIDIA-apex-39e153a to build tracker '/tmp/pip-req-tracker-8txmqvn6'\r\n",
      "    Running setup.py (path:/tmp/pip-req-build-nj3yyggs/setup.py) egg_info for package from file:///kaggle/input/nvidiaapex/repository/NVIDIA-apex-39e153a\r\n",
      "    Running command python setup.py egg_info\r\n",
      "    torch.__version__  =  1.0.1.post2\r\n",
      "    running egg_info\r\n",
      "    creating pip-egg-info/apex.egg-info\r\n",
      "    writing pip-egg-info/apex.egg-info/PKG-INFO\r\n",
      "    writing dependency_links to pip-egg-info/apex.egg-info/dependency_links.txt\r\n",
      "    writing top-level names to pip-egg-info/apex.egg-info/top_level.txt\r\n",
      "    writing manifest file 'pip-egg-info/apex.egg-info/SOURCES.txt'\r\n",
      "    reading manifest file 'pip-egg-info/apex.egg-info/SOURCES.txt'\r\n",
      "    writing manifest file 'pip-egg-info/apex.egg-info/SOURCES.txt'\r\n",
      "  Source in /tmp/pip-req-build-nj3yyggs has version 0.1, which satisfies requirement apex==0.1 from file:///kaggle/input/nvidiaapex/repository/NVIDIA-apex-39e153a\r\n",
      "  Removed apex==0.1 from file:///kaggle/input/nvidiaapex/repository/NVIDIA-apex-39e153a from build tracker '/tmp/pip-req-tracker-8txmqvn6'\r\n",
      "Installing collected packages: apex\r\n",
      "  Created temporary directory: /tmp/pip-record-74npfvjh\r\n",
      "  Running setup.py install for apex ... \u001b[?25l    Running command /opt/conda/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-req-build-nj3yyggs/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" --cpp_ext --cuda_ext install --record /tmp/pip-record-74npfvjh/install-record.txt --single-version-externally-managed --compile\r\n",
      "    torch.__version__  =  1.0.1.post2\r\n",
      "\r\n",
      "    Compiling cuda extensions with\r\n",
      "    nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "    Copyright (c) 2005-2018 NVIDIA Corporation\r\n",
      "    Built on Sat_Aug_25_21:08:01_CDT_2018\r\n",
      "    Cuda compilation tools, release 10.0, V10.0.130\r\n",
      "    from /usr/local/cuda/bin\r\n",
      "\r\n",
      "    Pytorch binaries were compiled with Cuda 10.0.130\r\n",
      "\r\n",
      "    running install\r\n",
      "    running build\r\n",
      "    running build_py\r\n",
      "    creating build\r\n",
      "    creating build/lib.linux-x86_64-3.6\r\n",
      "    creating build/lib.linux-x86_64-3.6/apex\r\n",
      "    copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\r\n",
      "    creating build/lib.linux-x86_64-3.6/apex/fp16_utils\r\n",
      "    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\r\n",
      "    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\r\n",
      "    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\r\n",
      "    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\r\n",
      "    creating build/lib.linux-x86_64-3.6/apex/reparameterization\r\n",
      "    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\r\n",
      "    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\r\n",
      "    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\r\n",
      "    creating build/lib.linux-x86_64-3.6/apex/parallel\r\n",
      "    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\r\n",
      "    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\r\n",
      "    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\r\n",
      "    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\r\n",
      "    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\r\n",
      "    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\r\n",
      "    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\r\n",
      "    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\r\n",
      "    creating build/lib.linux-x86_64-3.6/apex/normalization\r\n",
      "    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\r\n",
      "    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\r\n",
      "    creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\r\n",
      "    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\r\n",
      "    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\r\n",
      "    creating build/lib.linux-x86_64-3.6/apex/RNN\r\n",
      "    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\r\n",
      "    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\r\n",
      "    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\r\n",
      "    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\r\n",
      "    creating build/lib.linux-x86_64-3.6/apex/optimizers\r\n",
      "    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\r\n",
      "    copying apex/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/optimizers\r\n",
      "    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\r\n",
      "    creating build/lib.linux-x86_64-3.6/apex/amp\r\n",
      "    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\r\n",
      "    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\r\n",
      "    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\r\n",
      "    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\r\n",
      "    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\r\n",
      "    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\r\n",
      "    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\r\n",
      "    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\r\n",
      "    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\r\n",
      "    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\r\n",
      "    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\r\n",
      "    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\r\n",
      "    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\r\n",
      "    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\r\n",
      "    creating build/lib.linux-x86_64-3.6/apex/amp/lists\r\n",
      "    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\r\n",
      "    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\r\n",
      "    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\r\n",
      "    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\r\n",
      "    running build_ext\r\n",
      "    building 'apex_C' extension\r\n",
      "    creating build/temp.linux-x86_64-3.6\r\n",
      "    creating build/temp.linux-x86_64-3.6/csrc\r\n",
      "    gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/opt/conda/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\r\n",
      "    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\r\n",
      "    g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\r\n",
      "    building 'amp_C' extension\r\n",
      "    gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\r\n",
      "    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\r\n",
      "    /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\r\n",
      "    /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\r\n",
      "    /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\r\n",
      "    g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so\r\n",
      "    building 'fused_adam_cuda' extension\r\n",
      "    gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/fused_adam_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_adam_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\r\n",
      "    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\r\n",
      "    /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/fused_adam_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_adam_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\r\n",
      "    g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda.o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/fused_adam_cuda.cpython-36m-x86_64-linux-gnu.so\r\n",
      "    building 'syncbn' extension\r\n",
      "    gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.6/csrc/syncbn.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\r\n",
      "    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\r\n",
      "    /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/welford.cu -o build/temp.linux-x86_64-3.6/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\r\n",
      "    g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/csrc/syncbn.o build/temp.linux-x86_64-3.6/csrc/welford.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so\r\n",
      "    building 'fused_layer_norm_cuda' extension\r\n",
      "    gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\r\n",
      "    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\r\n",
      "    /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\r\n",
      "    g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\r\n",
      "    running install_lib\r\n",
      "    copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> /opt/conda/lib/python3.6/site-packages\r\n",
      "    copying build/lib.linux-x86_64-3.6/fused_adam_cuda.cpython-36m-x86_64-linux-gnu.so -> /opt/conda/lib/python3.6/site-packages\r\n",
      "    copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> /opt/conda/lib/python3.6/site-packages\r\n",
      "    creating /opt/conda/lib/python3.6/site-packages/apex\r\n",
      "    creating /opt/conda/lib/python3.6/site-packages/apex/fp16_utils\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/fp16_utils\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> /opt/conda/lib/python3.6/site-packages/apex/fp16_utils\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> /opt/conda/lib/python3.6/site-packages/apex/fp16_utils\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> /opt/conda/lib/python3.6/site-packages/apex/fp16_utils\r\n",
      "    creating /opt/conda/lib/python3.6/site-packages/apex/reparameterization\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> /opt/conda/lib/python3.6/site-packages/apex/reparameterization\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> /opt/conda/lib/python3.6/site-packages/apex/reparameterization\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/reparameterization\r\n",
      "    creating /opt/conda/lib/python3.6/site-packages/apex/parallel\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> /opt/conda/lib/python3.6/site-packages/apex/parallel\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> /opt/conda/lib/python3.6/site-packages/apex/parallel\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> /opt/conda/lib/python3.6/site-packages/apex/parallel\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/parallel\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> /opt/conda/lib/python3.6/site-packages/apex/parallel\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> /opt/conda/lib/python3.6/site-packages/apex/parallel\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> /opt/conda/lib/python3.6/site-packages/apex/parallel\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> /opt/conda/lib/python3.6/site-packages/apex/parallel\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex\r\n",
      "    creating /opt/conda/lib/python3.6/site-packages/apex/normalization\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/normalization\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> /opt/conda/lib/python3.6/site-packages/apex/normalization\r\n",
      "    creating /opt/conda/lib/python3.6/site-packages/apex/multi_tensor_apply\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> /opt/conda/lib/python3.6/site-packages/apex/multi_tensor_apply\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/multi_tensor_apply\r\n",
      "    creating /opt/conda/lib/python3.6/site-packages/apex/RNN\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> /opt/conda/lib/python3.6/site-packages/apex/RNN\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> /opt/conda/lib/python3.6/site-packages/apex/RNN\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/RNN\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> /opt/conda/lib/python3.6/site-packages/apex/RNN\r\n",
      "    creating /opt/conda/lib/python3.6/site-packages/apex/optimizers\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/optimizers\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fp16_optimizer.py -> /opt/conda/lib/python3.6/site-packages/apex/optimizers\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> /opt/conda/lib/python3.6/site-packages/apex/optimizers\r\n",
      "    creating /opt/conda/lib/python3.6/site-packages/apex/amp\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\r\n",
      "    creating /opt/conda/lib/python3.6/site-packages/apex/amp/lists\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> /opt/conda/lib/python3.6/site-packages/apex/amp/lists\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/amp/lists\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> /opt/conda/lib/python3.6/site-packages/apex/amp/lists\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> /opt/conda/lib/python3.6/site-packages/apex/amp/lists\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\r\n",
      "    copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> /opt/conda/lib/python3.6/site-packages\r\n",
      "    copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> /opt/conda/lib/python3.6/site-packages\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/parallel/__init__.py to __init__.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py to distributed.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/parallel/LARC.py to LARC.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/__init__.py to __init__.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/normalization/__init__.py to __init__.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/RNN/cells.py to cells.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/RNN/models.py to models.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/RNN/__init__.py to __init__.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/optimizers/__init__.py to __init__.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/__version__.py to __version__.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/compat.py to compat.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/__init__.py to __init__.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/utils.py to utils.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/opt.py to opt.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/scaler.py to scaler.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/amp.py to amp.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/_initialize.py to _initialize.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/frontend.py to frontend.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/handle.py to handle.cpython-36.pyc\r\n",
      "    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/wrap.py to wrap.cpython-36.pyc\r\n",
      "    running install_egg_info\r\n",
      "    running egg_info\r\n",
      "    creating apex.egg-info\r\n",
      "    writing apex.egg-info/PKG-INFO\r\n",
      "    writing dependency_links to apex.egg-info/dependency_links.txt\r\n",
      "    writing top-level names to apex.egg-info/top_level.txt\r\n",
      "    writing manifest file 'apex.egg-info/SOURCES.txt'\r\n",
      "    reading manifest file 'apex.egg-info/SOURCES.txt'\r\n",
      "    writing manifest file 'apex.egg-info/SOURCES.txt'\r\n",
      "    Copying apex.egg-info to /opt/conda/lib/python3.6/site-packages/apex-0.1-py3.6.egg-info\r\n",
      "    running install_scripts\r\n",
      "    writing list of installed files to '/tmp/pip-record-74npfvjh/install-record.txt'\r\n",
      "done\r\n",
      "\u001b[?25h  Removing source in /tmp/pip-req-build-nj3yyggs\r\n",
      "Successfully installed apex-0.1\r\n",
      "Cleaning up...\r\n",
      "Removed build tracker '/tmp/pip-req-tracker-8txmqvn6'\r\n",
      "1 location(s) to search for versions of pip:\r\n",
      "* https://pypi.org/simple/pip/\r\n",
      "Getting page https://pypi.org/simple/pip/\r\n",
      "Starting new HTTPS connection (1): pypi.org:443\r\n",
      "Could not fetch URL https://pypi.org/simple/pip/: connection error: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/pip/ (Caused by NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7f910b12ee48>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',)) - skipping\r\n"
     ]
    }
   ],
   "source": [
    "# Installing Nvidia Apex\n",
    "! pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ../input/nvidiaapex/repository/NVIDIA-apex-39e153a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apex import amp\n",
    "MAX_SEQUENCE_LENGTH = 200\n",
    "EPOCHS = 1\n",
    "Data_dir=\"../input/jigsaw-unintended-bias-in-toxicity-classification\"\n",
    "Input_dir = \"../input\"\n",
    "WORK_DIR = \"../working/\"\n",
    "\n",
    "device=torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STORING THE PRETRAINED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_dir_a = \"../input/gpt2-pytorch/pytorch-pretrained-bert-master/pytorch-pretrained-BERT-master/\"\n",
    "import sys\n",
    "sys.path.insert(0,package_dir_a)\n",
    "from pytorch_pretrained_bert import GPT2Tokenizer, GPT2ClassificationHeadModel,GPT2Config,OpenAIAdam\n",
    "\n",
    "identity_columns = [\n",
    "    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n",
    "    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "\n",
    "aux_cols=['target','severe_toxicity','obscene','identity_attack','insult','threat']\n",
    "\n",
    "gpt_config = GPT2Config(vocab_size_or_config_json_file=\"../input/gpt2-models/config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Total Data Shape (1804874, 200) (1804874, 7)\n",
      "CPU times: user 12.5 s, sys: 5.61 s, total: 18.1 s\n",
      "Wall time: 19.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = np.load(\"../input/train-lines-for-gpt2/lines_array_max_length_200.npy\")\n",
    "\n",
    "train = pd.read_csv(\"../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv\")\n",
    "\n",
    "train[identity_columns]=train[identity_columns].fillna(0)\n",
    "\n",
    "aux_cols=['target','severe_toxicity','obscene','identity_attack','insult','threat']\n",
    "print(len(aux_cols))\n",
    "y_aux=train[aux_cols].values\n",
    "train['target']=(train['target']>=0.5).astype(int)\n",
    "y=train['target'].values\n",
    "\n",
    "y=np.hstack((y.reshape(-1,1),y_aux))\n",
    "\n",
    "print(\"Total Data Shape\",X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1212,   318,   523,  3608,    13,   632,   338,   588,    11,\n",
       "         705, 19188,   345,   765,   534,  2802,   284,  1100,   428,\n",
       "        3548,     6, 16123,  1049,  2126,    11,   880,  1760,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78609906, 0.78609906, 0.78609906, 0.78609906, 1.57219811,\n",
       "       1.57219811, 0.78609906, 0.78609906, 0.78609906, 0.78609906])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taken from the kernel https://www.kaggle.com/tanreinama/simple-lstm-using-identity-parameters-solution\n",
    "weights=np.ones((train.shape[0],))\n",
    "weights = weights + train[identity_columns].sum(axis=1).astype(np.bool).astype(np.int).values\n",
    "\n",
    "# Background Positive, Subgroup Negative\n",
    "weights = weights + (( (train['target']>=0.5).astype(np.bool).astype(np.int) +  \\\n",
    "        (train[identity_columns].fillna(0).values<0.5).sum(axis=1).astype(np.int).astype(np.bool) )>1)\\\n",
    "                    .astype(np.bool).astype(np.int)\n",
    "\n",
    "# Background Negative, Subgroup Positive\n",
    "weights = weights + (( (train['target']<0.5).astype(np.bool).astype(np.int) + \\\n",
    "        (train[identity_columns].fillna(0).values>=0.5).sum(axis=1).astype(np.int).astype(np.bool) )>1)\\\n",
    "                    .astype(np.bool).astype(np.int)\n",
    "weights=(weights.values)/np.mean(weights)\n",
    "weights[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from the kernel https://www.kaggle.com/dborkan/benchmark-kernel\n",
    "SUBGROUP_AUC = 'subgroup_auc'\n",
    "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n",
    "\n",
    "# making subgroups as 1 and 0 with threshold 0.5\n",
    "# the nan value in some examples \n",
    "for subgroup in identity_columns:\n",
    "    train[subgroup]=(train[subgroup]>=0.5).astype(np.int8)\n",
    "\n",
    "def auc_score(y_true,y_pred):\n",
    "    return roc_auc_score(y_true,y_pred)\n",
    "\n",
    "def compute_bpsn(df,subgroup):\n",
    "    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\n",
    "    Here, we restrict the test set to the non-toxic examples that mention the identity and \n",
    "    the toxic examples that do not\"\"\"\n",
    "    \n",
    "    subgroup_negative_examples=df.loc[(df[subgroup]==1) & (df['target']==0)]\n",
    "    non_subgroup_positive_examples=df.loc[(df[subgroup]==0)&(df['target']==1)]\n",
    "    examples=pd.concat([subgroup_negative_examples,non_subgroup_positive_examples])\n",
    "    \n",
    "    return roc_auc_score(examples['target'].values,examples['preds'].values)\n",
    "    \n",
    "    \n",
    "def compute_bnsp(df,subgroup):\n",
    "    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\n",
    "    Here, we restrict the test set to the toxic examples that mention the identity and \n",
    "    the non-toxic examples that do not.\"\"\"\n",
    "    subgroup_positive_examples=df.loc[(df[subgroup]==1)&(df['target']==1)]\n",
    "    non_subgroup_negative_examples=df.loc[(df[subgroup]==0)&(df['target']==0)]\n",
    "    examples=pd.concat([subgroup_positive_examples,non_subgroup_negative_examples])\n",
    "    \n",
    "    return roc_auc_score(examples['target'].values,examples['preds'].values)\n",
    "\n",
    "def compute_bias_auc(indices=None,preds=None,df=None):\n",
    "    \"\"\" Computes the three auc for all the subgroups \"\"\"\n",
    "    if df is None:\n",
    "        df=train.copy()\n",
    "        df['preds']=preds\n",
    "        df=df.loc[indices].copy()\n",
    "    \n",
    "    records=[]\n",
    "    for subgroup in identity_columns:\n",
    "        record={\n",
    "            'subgroup': subgroup,\n",
    "            'subgroup_size': df.loc[df[subgroup]==1].shape[0]\n",
    "        }\n",
    "        record[SUBGROUP_AUC]=roc_auc_score(df.loc[df[subgroup]==1,'target'].values,\n",
    "                                                       df.loc[df[subgroup]==1,'preds'].values)\n",
    "        record[BPSN_AUC]=compute_bpsn(df,subgroup)\n",
    "        record[BNSP_AUC]=compute_bnsp(df,subgroup)\n",
    "        records.append(record)\n",
    "    \n",
    "    return pd.DataFrame(records)[['subgroup','subgroup_size',SUBGROUP_AUC,BPSN_AUC,BNSP_AUC]]\n",
    "\n",
    "def compute_power_mean(series,p):\n",
    "    total=np.sum(np.power(series,p))\n",
    "    return np.power(total/len(series),1/p)\n",
    "\n",
    "def compute_final_metric(indices,preds,overall_auc=None,p=-5,w=0.25):\n",
    "    df=train.copy()\n",
    "    df=df.loc[indices].copy()\n",
    "    df['preds']=preds\n",
    "    \n",
    "    if overall_auc is None:\n",
    "        overall_auc=roc_auc_score(df['target'],df['preds'])\n",
    "    bias_df=compute_bias_auc(df=df)\n",
    "    bias_score=np.average([\n",
    "        compute_power_mean(bias_df[SUBGROUP_AUC],p),\n",
    "        compute_power_mean(bias_df[BPSN_AUC],p),\n",
    "        compute_power_mean(bias_df[BNSP_AUC],p),\n",
    "    ])\n",
    "    \n",
    "    return bias_df,w*overall_auc+(1-w)*bias_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPLITTING THE DATA TO TRAIN AND VALDIATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "Training Shape (1353655, 200) (1353655, 7)\n",
      "Validation Shape (451219, 200) (451219, 7)\n"
     ]
    }
   ],
   "source": [
    "n_folds = 4\n",
    "kfold=StratifiedKFold(n_splits=n_folds,shuffle=True,random_state=SEED)\n",
    "oof_preds = np.zeros((X.shape[0],))\n",
    "\n",
    "for fold,(train_index,val_index) in enumerate(kfold.split(X,train['target'].values)):\n",
    "    if fold == 0:\n",
    "        FOLD = fold\n",
    "        X_train,X_val = X[train_index].copy(),X[val_index].copy()\n",
    "        y_train,y_val = y[train_index].copy(),y[val_index].copy()\n",
    "        weights_train = weights[train_index].copy()\n",
    "        val_indices = val_index\n",
    "        train_indices = train_index\n",
    "        \n",
    "        gc.enable()\n",
    "        del X,y,weights\n",
    "        print(gc.collect())\n",
    "        break\n",
    "        \n",
    "print(\"Training Shape\",X_train.shape,y_train.shape)\n",
    "print(\"Validation Shape\",X_val.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting the X_train and y_train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting ready for the train data_set\n",
    "train_dataset = torch.utils.data.TensorDataset(torch.tensor(X_train.copy(),dtype=torch.long), \\\n",
    "                                               torch.tensor(y_train.copy(),dtype=torch.float) , \\\n",
    "                                               torch.tensor(weights_train.copy(),dtype=torch.float))\n",
    "\n",
    "print(\"Deleting the X_train and y_train\")\n",
    "gc.enable()\n",
    "del X_train,y_train,weights_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOSS FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BceLoss(nn.Module):\n",
    "    def __init__(self,eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self,y_true,y_pred,weights=None):\n",
    "        \"\"\"\n",
    "        Computes the BCE Loss with respect to y_true\n",
    "        Weights is of shape : (batch_size,)\n",
    "        \"\"\"\n",
    "        y_pred = self.sigmoid(y_pred)\n",
    "        \n",
    "        if weights is None:\n",
    "            weights = torch.ones((y_true.shape[0],)).type('torch.FloatTensor').cuda()\n",
    "        \n",
    "        y_pred = torch.clamp(y_pred,self.eps,1-self.eps)\n",
    "        m = y_pred.shape[0]\n",
    "        \n",
    "        if len(y_true.shape)==1:\n",
    "            # changing y_true and y_pred \n",
    "            y_true = torch.unsqueeze(y_true,1)\n",
    "            y_pred = torch.unsqueeze(y_pred,1)\n",
    "        loss = torch.sum(y_true*torch.log(y_pred)+(1-y_true)*torch.log(1-y_pred),dim=1)\n",
    "#         print(y_true.shape,y_pred.shape,loss.shape)\n",
    "        loss = -torch.sum(weights*loss)/m\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "class BinaryFocalLoss(nn.Module):\n",
    "    def __init__(self,gamma=0,eps=1e-3):\n",
    "        super().__init__()\n",
    "        self.gamma=gamma\n",
    "        self.eps=eps\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self,y_true,y_pred,weights=None):\n",
    "        \n",
    "        y_pred = self.sigmoid(y_pred)\n",
    "        \n",
    "        if weights is None:\n",
    "            weights = torch.ones((y_true.shape[0],)).type('torch.FloatTensor').cuda()\n",
    "\n",
    "        y_pred = torch.clamp(y_pred,self.eps,1-self.eps)\n",
    "        m = y_pred.shape[0]\n",
    "        \n",
    "        if len(y_true.shape)==1:\n",
    "            # changing the shape of y_pred and y_true\n",
    "            y_true = torch.unsqueeze(y_true,1)\n",
    "            y_pred = torch.unsqueeze(y_pred,1)\n",
    "        \n",
    "        loss = torch.sum(y_true*torch.pow(1-y_pred,self.gamma)*torch.log(y_pred) + \\\n",
    "               (1-y_true)*torch.pow(y_pred,self.gamma)*torch.log(1-y_pred),dim=1)\n",
    "        \n",
    "        loss = -torch.sum(weights*loss)/m\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_file = \"fine_tuned_gpt2_fold_\"+str(FOLD+1)+\"_seed_\"+str(SEED)+\".bin\"\n",
    "\n",
    "lr = 5e-5\n",
    "batch_size = 32\n",
    "accumulation_steps = 2                  # number of backprops to calculate for the update."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 7416/42302 [1:21:13<6:24:36,  1.51it/s]"
     ]
    }
   ],
   "source": [
    "model = GPT2ClassificationHeadModel.from_pretrained(pretrained_model_name_or_path=\"../input/gpt2-models/\",clf_dropout=0.4,\n",
    "                                                    n_class = len(aux_cols)+1)\n",
    "model.zero_grad()\n",
    "model.cuda()\n",
    "\n",
    "loss_fn = BinaryFocalLoss(gamma = 2)\n",
    "\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "num_train_optimization_steps = int(EPOCHS*len(train_dataset)/batch_size/accumulation_steps)\n",
    "\n",
    "optimizer = OpenAIAdam(optimizer_grouped_parameters, \n",
    "                       lr=lr,\n",
    "                       warmup=0.05,\n",
    "                       t_total=num_train_optimization_steps)\n",
    "\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle = True)\n",
    "# loss_values = []\n",
    "for epoch in range(EPOCHS):\n",
    "    optimizer.zero_grad()\n",
    "    for batch,(X_train,y_train,weights) in tqdm(enumerate(train_loader),total=len(train_loader),leave=False):\n",
    "        X_train = X_train.cuda()\n",
    "        y_train = y_train.cuda()\n",
    "        weights = weights.cuda()\n",
    "        y_pred = model.forward(X_train)\n",
    "        loss = loss_fn(y_train,y_pred,weights)\n",
    "#         loss_values.append(loss)\n",
    "#         import pdb ; pdb.set_trace()\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "        if (batch+1) % accumulation_steps == 0:             # Wait for several backward steps\n",
    "            optimizer.step()                            # Now we can do an optimizer step\n",
    "            optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model            \n",
    "torch.save(model.state_dict(), output_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deleting the things that we don't need\n",
    "gc.enable()\n",
    "del train_dataset,train_loader,model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    }
   ],
   "source": [
    "# Run validation\n",
    "model = GPT2ClassificationHeadModel(gpt_config,clf_dropout=0.4,n_class=len(aux_cols)+1)\n",
    "model.load_state_dict(torch.load(output_model_file))\n",
    "model.cuda()\n",
    "for param in model.parameters():\n",
    "    param.requires_grad=False\n",
    "model.eval()\n",
    "# X_val = np.zeros((20000,200))\n",
    "batch_size = 128\n",
    "valid_preds = np.zeros((X_val.shape[0],))\n",
    "valid_dataset = TensorDataset(torch.tensor(X_val,dtype=torch.long))\n",
    "valid_loader = DataLoader(valid_dataset,batch_size=batch_size,shuffle = False)\n",
    "val_index = 0\n",
    "for batch,(X_val,) in  tqdm(enumerate(valid_loader),total = len(valid_loader),leave = False):\n",
    "    X_val = X_val.cuda()\n",
    "    y_pred = model.forward(X_val)\n",
    "    valid_preds[val_index:val_index+X_val.shape[0]] = y_pred[:,0].cpu().detach().numpy().reshape((-1,))\n",
    "    val_index = val_index + X_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9376397865158378\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subgroup</th>\n",
       "      <th>subgroup_size</th>\n",
       "      <th>subgroup_auc</th>\n",
       "      <th>bpsn_auc</th>\n",
       "      <th>bnsp_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>11104</td>\n",
       "      <td>0.932398</td>\n",
       "      <td>0.946864</td>\n",
       "      <td>0.962621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>13407</td>\n",
       "      <td>0.929282</td>\n",
       "      <td>0.949486</td>\n",
       "      <td>0.959423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "      <td>2780</td>\n",
       "      <td>0.868999</td>\n",
       "      <td>0.888718</td>\n",
       "      <td>0.965972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>christian</td>\n",
       "      <td>10050</td>\n",
       "      <td>0.937523</td>\n",
       "      <td>0.965937</td>\n",
       "      <td>0.946866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jewish</td>\n",
       "      <td>1868</td>\n",
       "      <td>0.905857</td>\n",
       "      <td>0.937881</td>\n",
       "      <td>0.954745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>muslim</td>\n",
       "      <td>5271</td>\n",
       "      <td>0.881239</td>\n",
       "      <td>0.917447</td>\n",
       "      <td>0.958869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>black</td>\n",
       "      <td>3653</td>\n",
       "      <td>0.858428</td>\n",
       "      <td>0.886464</td>\n",
       "      <td>0.964542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>white</td>\n",
       "      <td>6228</td>\n",
       "      <td>0.862236</td>\n",
       "      <td>0.892632</td>\n",
       "      <td>0.964781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "      <td>1242</td>\n",
       "      <td>0.939351</td>\n",
       "      <td>0.935404</td>\n",
       "      <td>0.971645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        subgroup  subgroup_size    ...     bpsn_auc  bnsp_auc\n",
       "0                           male          11104    ...     0.946864  0.962621\n",
       "1                         female          13407    ...     0.949486  0.959423\n",
       "2      homosexual_gay_or_lesbian           2780    ...     0.888718  0.965972\n",
       "3                      christian          10050    ...     0.965937  0.946866\n",
       "4                         jewish           1868    ...     0.937881  0.954745\n",
       "5                         muslim           5271    ...     0.917447  0.958869\n",
       "6                          black           3653    ...     0.886464  0.964542\n",
       "7                          white           6228    ...     0.892632  0.964781\n",
       "8  psychiatric_or_mental_illness           1242    ...     0.935404  0.971645\n",
       "\n",
       "[9 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.7 s, sys: 848 ms, total: 5.55 s\n",
      "Wall time: 5.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "m,l = compute_final_metric(val_indices,valid_preds)\n",
    "print(l)\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1804874, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59848</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59849</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59852</td>\n",
       "      <td>-3.037109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59855</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59856</td>\n",
       "      <td>1.761719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  prediction\n",
       "0  59848    0.000000\n",
       "1  59849    0.000000\n",
       "2  59852   -3.037109\n",
       "3  59855    0.000000\n",
       "4  59856    1.761719"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_preds[val_indices] = valid_preds\n",
    "oof=pd.DataFrame()\n",
    "oof['id']=train['id']\n",
    "oof['prediction']=oof_preds\n",
    "oof.to_csv(\"oof.csv\",index=False)\n",
    "print(oof.shape)\n",
    "oof.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
